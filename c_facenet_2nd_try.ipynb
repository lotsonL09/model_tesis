{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Tesis\\Tesis\\Codigo\\model_pytorch\\venv2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import tqdm\n",
    "from tqdm.auto import tqdm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gpus: 1\n"
     ]
    }
   ],
   "source": [
    "#GPUS\n",
    "n_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of gpus: {n_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock (nn.Module):\n",
    "    def __init__(self,\n",
    "                in_channels: int,\n",
    "                out_channels: int,\n",
    "                 **kwargs): # this means that the key arguments are arbitrary\n",
    "        super().__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                            out_channels=out_channels,\n",
    "                              **kwargs,\n",
    "                            device=device)\n",
    "        self.batchnorm = nn.BatchNorm2d(num_features=out_channels) # to improve performance\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2NormLayer(nn.Module):\n",
    "    def __init__(self,dim=1):\n",
    "        super().__init__()\n",
    "        self.dim=dim\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return nn.functional.normalize(x,p=2,dim=self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock (nn.Module):\n",
    "        def __init__(self,\n",
    "                in_channels: int,\n",
    "                out_1x1: int,\n",
    "\n",
    "                red_3x3: int,\n",
    "                out_3x3: int,\n",
    "\n",
    "                red_5x5: int,\n",
    "                out_5x5: int,\n",
    "\n",
    "                out_1x1pool: int,\n",
    "                \n",
    "                l2_mode:bool=False):\n",
    "        \n",
    "                super().__init__()\n",
    "\n",
    "                self.branch1 = ConvBlock(in_channels=in_channels,\n",
    "                                        out_channels=out_1x1,\n",
    "                                        kernel_size=1)\n",
    "                \n",
    "                self.branch2 = nn.Sequential(\n",
    "                        ConvBlock(in_channels=in_channels,\n",
    "                                out_channels=red_3x3,\n",
    "                                kernel_size=1),\n",
    "                        ConvBlock(in_channels=red_3x3,\n",
    "                                out_channels=out_3x3,\n",
    "                                kernel_size=3,\n",
    "                                padding=1) # ojo (btw no ponemos el S bc por defecto es 1)\n",
    "                )\n",
    "                \n",
    "                self.branch3 = nn.Sequential(\n",
    "                        ConvBlock(in_channels=in_channels,\n",
    "                                out_channels=red_5x5,\n",
    "                                kernel_size=1),\n",
    "                        ConvBlock(in_channels=red_5x5,\n",
    "                                out_channels=out_5x5,\n",
    "                                kernel_size=5,\n",
    "                                padding=2) # ojo (btw no ponemos el S bc por defecto es 1)\n",
    "                )\n",
    "\n",
    "                if l2_mode:\n",
    "                        self.branch4=nn.Sequential(\n",
    "                                L2NormLayer(dim=1),\n",
    "                                ConvBlock(in_channels=in_channels,\n",
    "                                out_channels=out_1x1pool,\n",
    "                                kernel_size=1)\n",
    "                        )\n",
    "                else:\n",
    "                        self.branch4 = nn.Sequential(\n",
    "                                nn.MaxPool2d(kernel_size=3,stride=1,padding=1),\n",
    "                                ConvBlock(in_channels=in_channels,\n",
    "                                        out_channels=out_1x1pool,\n",
    "                                        kernel_size=1)\n",
    "                        )\n",
    "\n",
    "        def forward(self,x):\n",
    "        # N x filters x 28 x 28 → 0th x 1st x 2nd x 3rd dimension (we use 1)\n",
    "                return torch.cat([self.branch1(x),self.branch2(x),self.branch3(x),self.branch4(x)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock_2(nn.Module):\n",
    "    def __init__(self, \n",
    "                in_channels:int, \n",
    "                red_3x3:int,\n",
    "                out_3x3:int) -> None:\n",
    "        super().__init__()\n",
    "        self.branch=nn.Sequential(\n",
    "            ConvBlock(in_channels=in_channels,\n",
    "                    out_channels=red_3x3,\n",
    "                    kernel_size=1),\n",
    "            ConvBlock(in_channels=red_3x3,\n",
    "                    out_channels=out_3x3,\n",
    "                    kernel_size=3)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.branch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock_m_3x3 (nn.Module):\n",
    "        def __init__(self,\n",
    "                in_channels: int,\n",
    "\n",
    "                red_3x3: int,\n",
    "                out_3x3: int,\n",
    "\n",
    "                red_5x5: int,\n",
    "                out_5x5: int):\n",
    "        \n",
    "                super().__init__()\n",
    "\n",
    "                self.branch2 = nn.Sequential(\n",
    "                        ConvBlock(in_channels=in_channels,\n",
    "                                out_channels=red_3x3,\n",
    "                                kernel_size=1),\n",
    "                        ConvBlock(in_channels=red_3x3,\n",
    "                                out_channels=out_3x3,\n",
    "                                kernel_size=3,\n",
    "                                padding=1,\n",
    "                                stride=2) # ojo (btw no ponemos el S bc por defecto es 1)\n",
    "                )\n",
    "                \n",
    "                self.branch3 = nn.Sequential(\n",
    "                        ConvBlock(in_channels=in_channels,\n",
    "                                out_channels=red_5x5,\n",
    "                                kernel_size=1),\n",
    "                        ConvBlock(in_channels=red_5x5,\n",
    "                                out_channels=out_5x5,\n",
    "                                kernel_size=5,\n",
    "                                padding=2,\n",
    "                                stride=2) # ojo (btw no ponemos el S bc por defecto es 1)\n",
    "                )\n",
    "\n",
    "                self.branch4 = nn.Sequential(\n",
    "                        nn.MaxPool2d(kernel_size=3,stride=2,padding=1), #TODO: VERIFICAR LO DEL PADDING CON JAVIER\n",
    "                )\n",
    "\n",
    "        def forward(self,x):\n",
    "        # N x filters x 28 x 28 → 0th x 1st x 2nd x 3rd dimension (we use 1)\n",
    "                return torch.cat([self.branch2(x),self.branch3(x),self.branch4(x)],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN2 (nn.Module):\n",
    "    def __init__(self,\n",
    "                in_channels = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = ConvBlock(in_channels=in_channels,\n",
    "                            out_channels=64,\n",
    "                            kernel_size=7,\n",
    "                            stride=2,\n",
    "                            padding=3)\n",
    "        \n",
    "        self.inception2 = InceptionBlock_2(in_channels=64, #la cantidad de canales que entran y salen es la misma. ¿esto es correcto?\n",
    "                                        red_3x3=64,\n",
    "                                        out_3x3=192)\n",
    "        \n",
    "        self.inception3a = InceptionBlock( in_channels= 192, out_1x1= 64, red_3x3= 96, out_3x3= 128, red_5x5= 16,out_5x5= 32, out_1x1pool= 32)#ok\n",
    "        self.inception3b = InceptionBlock( in_channels= 256, out_1x1= 64, red_3x3= 96, out_3x3= 128, red_5x5= 32,out_5x5= 64, out_1x1pool= 64,l2_mode=True)\n",
    "        #modificar desactivando branch 1 y 4\n",
    "        self.inception3c = InceptionBlock_m_3x3( in_channels= 320, red_3x3= 128, out_3x3= 256, red_5x5= 32,out_5x5= 64)\n",
    "        \n",
    "        self.inception4a = InceptionBlock( in_channels= 640, out_1x1= 256, red_3x3= 96, out_3x3= 192, red_5x5= 32,out_5x5= 64, out_1x1pool= 128,l2_mode=True)\n",
    "        self.inception4b = InceptionBlock( in_channels= 640, out_1x1= 224, red_3x3= 112, out_3x3= 224, red_5x5= 32,out_5x5= 64, out_1x1pool= 128,l2_mode=True)\n",
    "        self.inception4c = InceptionBlock( in_channels= 640, out_1x1= 192, red_3x3= 128, out_3x3= 256, red_5x5= 32,out_5x5= 64, out_1x1pool= 128,l2_mode=True)\n",
    "        self.inception4d = InceptionBlock( in_channels= 640, out_1x1= 160, red_3x3= 144, out_3x3= 288, red_5x5= 32,out_5x5= 64, out_1x1pool= 128,l2_mode=True)\n",
    "        #modificar desactivando branch 1 y 4\n",
    "        self.inception4e = InceptionBlock_m_3x3( in_channels= 640, red_3x3= 160, out_3x3= 256, red_5x5= 64,out_5x5= 128)\n",
    "        \n",
    "        self.inception5a = InceptionBlock( in_channels= 1024, out_1x1= 384, red_3x3= 192, out_3x3= 384, red_5x5= 48,out_5x5= 128, out_1x1pool= 128,l2_mode=True)\n",
    "        self.inception5b = InceptionBlock( in_channels= 1024, out_1x1= 384, red_3x3= 192, out_3x3= 384, red_5x5= 48,out_5x5= 128, out_1x1pool= 128)#ok\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1) #por que se aplico un max pool?\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=7) # stride? padding?\n",
    "        \n",
    "        self.FC = nn.Linear(1024,128)\n",
    "\n",
    "        self.norm=nn.BatchNorm2d(num_features=64)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x=self.norm(x)\n",
    "\n",
    "        x = self.inception2(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.inception3c(x)\n",
    "\n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        #print('Despues del inception 5b',x.shape)\n",
    "        x = self.avgpool(x)\n",
    "        #print('Despues del avg pool',x.shape)\n",
    "\n",
    "        x=x.view(x.shape[0],-1)\n",
    "\n",
    "        x = self.FC(x)\n",
    "        #print('Despues de fully connected layer',x.shape)\n",
    "        x = nn.functional.normalize(x,p=2,dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = NN2(in_channels=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample de prueba\n",
    "\n",
    "sample=torch.randn(size=(1,3,224,224)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    model_1(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)),  #Para pasar a 224 x 224 pixels\n",
    "    transforms.ToTensor()          #Para convertir la imagen a tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Tesis\\Tesis\\Codigo\\model_pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/train')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_data_path=Path('data')\n",
    "train_path=root_data_path / 'train'\n",
    "\n",
    "test_path=root_data_path / 'test'\n",
    "\n",
    "train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path_list=list(test_path.glob('*/*.jpg'))\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "random_image_path=random.choice(img_path_list)\n",
    "img=Image.open(random_image_path)\n",
    "\n",
    "transform(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=torchvision.datasets.ImageFolder(train_path,\n",
    "                                        transform=transform,\n",
    "                                        target_transform=None)\n",
    "\n",
    "test_data=torchvision.datasets.ImageFolder(test_path,\n",
    "                                        transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data\\\\train\\\\cinthia\\\\rostro_0.jpg', 0),\n",
       " ('data\\\\train\\\\cinthia\\\\rostro_1.jpg', 0),\n",
       " ('data\\\\train\\\\cinthia\\\\rostro_2.jpg', 0),\n",
       " ('data\\\\train\\\\cinthia\\\\rostro_3.jpg', 0),\n",
       " ('data\\\\train\\\\cinthia\\\\rostro_4.jpg', 0),\n",
       " ('data\\\\train\\\\cinthia\\\\rostro_5.jpg', 0),\n",
       " ('data\\\\train\\\\cinthia\\\\rostro_6.jpg', 0),\n",
       " ('data\\\\train\\\\cinthia\\\\rostro_7.jpg', 0),\n",
       " ('data\\\\train\\\\cinthia\\\\rostro_8.jpg', 0),\n",
       " ('data\\\\train\\\\cinthia\\\\rostro_9.jpg', 0),\n",
       " ('data\\\\train\\\\wia\\\\rostro_0.jpg', 1),\n",
       " ('data\\\\train\\\\wia\\\\rostro_1.jpg', 1),\n",
       " ('data\\\\train\\\\wia\\\\rostro_2.jpg', 1),\n",
       " ('data\\\\train\\\\wia\\\\rostro_3.jpg', 1),\n",
       " ('data\\\\train\\\\wia\\\\rostro_4.jpg', 1),\n",
       " ('data\\\\train\\\\wia\\\\rostro_5.jpg', 1),\n",
       " ('data\\\\train\\\\wia\\\\rostro_6.jpg', 1),\n",
       " ('data\\\\train\\\\wia\\\\rostro_7.jpg', 1),\n",
       " ('data\\\\train\\\\wia\\\\rostro_8.jpg', 1),\n",
       " ('data\\\\train\\\\wia\\\\rostro_9.jpg', 1),\n",
       " ('data\\\\train\\\\william\\\\rostro_0.jpg', 2),\n",
       " ('data\\\\train\\\\william\\\\rostro_1.jpg', 2),\n",
       " ('data\\\\train\\\\william\\\\rostro_2.jpg', 2),\n",
       " ('data\\\\train\\\\william\\\\rostro_3.jpg', 2),\n",
       " ('data\\\\train\\\\william\\\\rostro_4.jpg', 2),\n",
       " ('data\\\\train\\\\william\\\\rostro_5.jpg', 2),\n",
       " ('data\\\\train\\\\william\\\\rostro_6.jpg', 2),\n",
       " ('data\\\\train\\\\william\\\\rostro_7.jpg', 2),\n",
       " ('data\\\\train\\\\william\\\\rostro_8.jpg', 2),\n",
       " ('data\\\\train\\\\william\\\\rostro_9.jpg', 2)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 30\n",
       "    Root location: data\\train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 6\n",
       "    Root location: data\\test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=train_data,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=2,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_loader=DataLoader(dataset=test_data,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=2,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch,label_batch=next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(params=model_1.parameters(),\n",
    "                    lr=0.1)\n",
    "loss_fn=nn.TripletMarginLoss(margin=0.2,p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cinthia': 0, 'wia': 1, 'william': 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [], 1: [], 2: []}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_reference=dict()\n",
    "for key,value in train_data.class_to_idx.items():\n",
    "    dict_reference[value]=[]\n",
    "\n",
    "dict_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(dict_reference.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_images,batch_labels=next(iter(train_loader))\n",
    "batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_extracted():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #0\n",
      "Embeddings 0 5\n",
      "Embeddings 1 3\n",
      "Embeddings 2 2\n",
      "Useful case 0\n",
      "Useful case 1\n",
      "Useful case 2\n",
      "-------------------------------------------------\n",
      "Batch #1\n",
      "Embeddings 0 2\n",
      "Embeddings 1 5\n",
      "Embeddings 2 3\n",
      "Useful case 0\n",
      "Useful case 1\n",
      "Useful case 2\n",
      "-------------------------------------------------\n",
      "Batch #2\n",
      "Embeddings 0 3\n",
      "Embeddings 1 2\n",
      "Embeddings 2 5\n",
      "Useful case 0\n",
      "Useful case 1\n",
      "Useful case 2\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# #CODE\n",
    "\n",
    "# for batch, (X,y) in enumerate(train_loader):\n",
    "\n",
    "#     X,y=X.to(device),y.to(device)\n",
    "#     y_preds=model_1(X) #embedding vector\n",
    "\n",
    "#     # #loss=loss_fn(y_preds,y)\n",
    "#     # #optimizer.zero_grad()\n",
    "    \n",
    "#     # #loss_fn.backward()\n",
    "#     # #optimizer.step()\n",
    "\n",
    "#     print(f'Batch #{batch}')\n",
    "\n",
    "#     data_loss_triple_function = deepcopy(dict_reference) \n",
    "\n",
    "#     for embedding,label in zip(y_preds,y):\n",
    "#         data_loss_triple_function[(label.cpu().item())].append(embedding)\n",
    "    \n",
    "#     print('Embeddings 0',len(data_loss_triple_function[0]))\n",
    "#     print('Embeddings 1',len(data_loss_triple_function[1]))\n",
    "#     print('Embeddings 2',len(data_loss_triple_function[2]))\n",
    "#     # print('-------------------------------------------------')\n",
    "\n",
    "#     for clase in data_loss_triple_function.keys():\n",
    "#         if len(data_loss_triple_function[clase]) >1 :\n",
    "#             print('Useful case',clase)\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "#     print('-------------------------------------------------')\n",
    "\n",
    "#     # for elements in range(len(data_loss_triple_function.keys())):\n",
    "#     #     print(batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_step(\n",
    "#         model:nn.Module,\n",
    "#         dataloader:torch.utils.data.dataloader,\n",
    "#         loss_fn:nn.Module,\n",
    "#         optimizer:torch.optim.Optimizer,\n",
    "#         device):\n",
    "    \n",
    "#     model.train()\n",
    "\n",
    "#     train_loss,train_acc=0,0\n",
    "\n",
    "#     for batch, (X,y) in enumerate(dataloader):\n",
    "#         X,y=X.to(device),y.to(device)\n",
    "#         y_preds=model(X)\n",
    "#         loss=loss_fn(y_preds,y)\n",
    "#         train_loss+=loss\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         loss_fn.backward()\n",
    "\n",
    "#         optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from pytorch_metric_learning.reducers import ThresholdReducer\n",
    "from pytorch_metric_learning.regularizers import LpRegularizer\n",
    "from pytorch_metric_learning import losses\n",
    "from pytorch_metric_learning.miners import TripletMarginMiner\n",
    "\n",
    "distance=CosineSimilarity()\n",
    "reducer = ThresholdReducer(high=0.3)\n",
    "embedding_regularizer = LpRegularizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = losses.TripletMarginLoss(distance = CosineSimilarity(), \n",
    "                                    reducer = ThresholdReducer(high=0.3), \n",
    "                                    embedding_regularizer = LpRegularizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "minig_func_train=TripletMarginMiner(margin=0.2,distance=distance,type_of_triplets='hard')\n",
    "\n",
    "minig_func_test=TripletMarginMiner(margin=0.2,distance=distance,type_of_triplets='easy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "        model:torch.nn.Module,\n",
    "        dataloader:torch.utils.data.dataloader,\n",
    "        loss_fn:torch.nn.Module,\n",
    "        optimizer:torch.optim.Optimizer,\n",
    "        mining_func,\n",
    "        device):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    train_loss,train_acc=0,0\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        #Send data to the target device\n",
    "        X,y=X.to(device),y.to(device)\n",
    "\n",
    "        #1. Forward pass\n",
    "        embeddings=model(X) #Output model logits\n",
    "\n",
    "        indices_tuple=mining_func(embeddings,y)\n",
    "\n",
    "        #2. Calculate the loss\n",
    "\n",
    "        anchors=embeddings[indices_tuple[0]]\n",
    "        positives=embeddings[indices_tuple[0]]\n",
    "        negatives=embeddings[indices_tuple[0]]\n",
    "\n",
    "        loss=loss_fn(anchors,positives,negatives)\n",
    "\n",
    "        loss=torch.nan_to_num(loss,nan=0.0)\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "        #3.Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        #5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        #Calculate accuracy metric\n",
    "        # y_pred_class=torch.argmax(torch.softmax(embeddings,dim=1),dim=1)\n",
    "        # train_acc+= (y_pred_class == y).sum().item() / len(embeddings)\n",
    "\n",
    "    #Adjust metrics to get average loss and accuracy per batch\n",
    "    train_loss= train_loss/len(dataloader)\n",
    "    #train_acc=train_acc / len(dataloader)\n",
    "    print(train_loss)\n",
    "    #return train_loss,train_acc\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_model,train_acc_model=train_step(model=model_1,\n",
    "                                            dataloader=train_loader,\n",
    "                                            loss_fn=loss_fn,\n",
    "                                            optimizer=optimizer,\n",
    "                                            mining_func=minig_func_train,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333532015482"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "        model:torch.nn.Module,\n",
    "        dataloader:torch.utils.data.dataloader,\n",
    "        loss_fn:torch.nn.Module,\n",
    "        mining_func,\n",
    "        device=device):\n",
    "    \n",
    "    #Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss,test_acc=0,0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        #Loop through DataLoader batches\n",
    "\n",
    "        for batch, (X,y) in enumerate(dataloader):\n",
    "            #Send data to the target device\n",
    "            X,y=X.to(device),y.to(device)\n",
    "\n",
    "            #1. Forward pass\n",
    "            embeddings=model(X)\n",
    "\n",
    "            indices_tuple=mining_func(embeddings,y)\n",
    "\n",
    "            anchors=embeddings[indices_tuple[0]]\n",
    "            positives=embeddings[indices_tuple[0]]\n",
    "            negatives=embeddings[indices_tuple[0]]\n",
    "\n",
    "            #2. Calculate the loss\n",
    "            loss=loss_fn(anchors,positives,negatives)\n",
    "\n",
    "            loss=torch.nan_to_num(loss,nan=0.0)\n",
    "\n",
    "            test_loss+=loss.item()\n",
    "\n",
    "            #3. Calculate the accuracy\n",
    "            # test_preds_labels=torch.argmax(torch.softmax(embeddings,dim=1),dim=1)\n",
    "            # test_acc+= (test_preds_labels==y).sum().item() / len(test_preds_labels)\n",
    "\n",
    "    #Adjust the metrics to get averague loss and accuracy per batch\n",
    "    test_loss=test_loss / len(dataloader)\n",
    "    #test_acc=test_acc / len(dataloader)\n",
    "\n",
    "    #return test_loss,test_acc\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss=test_step(model=model_1,\n",
    "        dataloader=test_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        mining_func=minig_func_test,\n",
    "        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model:torch.nn.Module,\n",
    "        train_dataloader:torch.utils.data.dataloader,\n",
    "        test_dataloader:torch.utils.data.dataloader,\n",
    "        optimizer:torch.optim.Optimizer,\n",
    "        loss_fn:torch.nn.Module,\n",
    "        minig_func_train,\n",
    "        minig_func_test,\n",
    "        epochs=5,\n",
    "        device=device):\n",
    "    \n",
    "        #2. Create empty results dictionary\n",
    "        # results={\"train_loss\":[],\n",
    "        #         \"train_acc\":[],\n",
    "        #         \"test_loss\":[],\n",
    "        #         \"test_acc\":[]}\n",
    "\n",
    "        results={\"train_loss\":[],\n",
    "                \"test_loss\":[]}\n",
    "\n",
    "        #3. Loop through training and testing step for a number of epochs\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "                train_loss=train_step(model=model,\n",
    "                                    dataloader=train_dataloader,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    optimizer=optimizer,\n",
    "                                    mining_func=minig_func_train,\n",
    "                                    device=device)\n",
    "                test_loss=test_step(model=model,\n",
    "                                    dataloader=test_dataloader,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    mining_func=minig_func_test,\n",
    "                                    device=device)\n",
    "        \n",
    "                #4. Print out what's happening\n",
    "                #print('Train loss',train_loss)\n",
    "                #print('Test loss',test_loss)\n",
    "                print(f\"Epoch: {epoch} | Train loss:{train_loss} | Test loss : {test_loss}\")\n",
    "                #5. Update results diccionary\n",
    "                results[\"train_loss\"].append(train_loss)\n",
    "                results[\"test_loss\"].append(test_loss)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = NN2(in_channels=3).to(device)\n",
    "optimizer=optim.Adam(params=model_1.parameters(),\n",
    "                    lr=0.1)\n",
    "loss_fn=nn.TripletMarginLoss(margin=0.2,p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:05<00:48,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss:(0.13333334028720856, 0.0) | Test loss : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:10<00:43,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train loss:(0.13333334028720856, 0.0) | Test loss : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:15<00:36,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train loss:(0.13333333532015482, 0.0) | Test loss : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:21<00:31,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train loss:(0.20000000298023224, 0.0) | Test loss : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:26<00:26,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train loss:(0.20000000298023224, 0.0) | Test loss : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:31<00:21,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train loss:(0.06666666766007741, 0.0) | Test loss : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:37<00:15,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train loss:(0.13333334028720856, 0.0) | Test loss : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:42<00:10,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train loss:(0.06666666766007741, 0.0) | Test loss : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:48<00:05,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train loss:(0.06666666766007741, 0.0) | Test loss : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:53<00:00,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train loss:(0.20000000794728598, 0.0) | Test loss : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_model_1=train_model(\n",
    "    model=model_1,\n",
    "    train_dataloader=train_loader,\n",
    "    test_dataloader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    minig_func_train=minig_func_train,\n",
    "    minig_func_test=minig_func_test,\n",
    "    epochs=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [(0.13333334028720856, 0.0),\n",
       "  (0.13333334028720856, 0.0),\n",
       "  (0.13333333532015482, 0.0),\n",
       "  (0.20000000298023224, 0.0),\n",
       "  (0.20000000298023224, 0.0),\n",
       "  (0.06666666766007741, 0.0),\n",
       "  (0.13333334028720856, 0.0),\n",
       "  (0.06666666766007741, 0.0),\n",
       "  (0.06666666766007741, 0.0),\n",
       "  (0.20000000794728598, 0.0)],\n",
       " 'test_loss': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
